{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from random import randint\n",
    "from skimage.transform import radon\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "\n",
    "def single_square_data_generator(side_size : \"size of the square's side\",\n",
    "                                     ) -> \" (x,y) tuple \" :\n",
    "\n",
    "\n",
    "    img = np.zeros(side_size**2) # single 0s arr with all the points \n",
    "    img[: randint(0,side_size**2)]  = 1  # transform some random number of points into 1s\n",
    "    np.random.shuffle(img) # shuffle arr\n",
    "    img = np.reshape(img,(side_size,side_size)) # transform arr to a double arr\n",
    "\n",
    "    sinogram = radon(img) # sinogram transformation from skimage.transform library [ sinogram transf is called radon transform]\n",
    "    \n",
    "    return (sinogram, img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def square_data_generator(n : \"number of data to be generated\",\n",
    "                          side_size : \"size of the square's side\",\n",
    "                          ) -> \" (x,y) where x - list of sinograms, y - list of corresponding images\" :\n",
    "\n",
    "    x, y = [], []    \n",
    "    for _ in range(n):\n",
    "        sinogram, img = single_square_data_generator(side_size)\n",
    "        x.append(sinogram)\n",
    "        y.append(img)\n",
    "        \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #### To make it fit the NN we need to transform these to tensors, change their dimensions, and cast into double [float32]\n",
    "    \n",
    "    x = torch.from_numpy(x)\n",
    "    x = x.view(-1,1,64,180)\n",
    "    x = x.to(dtype=torch.float32)\n",
    "    \n",
    "    \n",
    "    #### Do we need to convert y to tensor as well? Probs yes so we use GPU to calculate Cross Entropy loss ?\n",
    "\n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastai/lib/python3.7/site-packages/skimage/transform/radon_transform.py:91: UserWarning: Radon transform: image must be zero outside the reconstruction circle\n",
      "  warn('Radon transform: image must be zero outside the '\n"
     ]
    }
   ],
   "source": [
    "# 8983 - nr of images used in CNN_paper, 64 - size of them\n",
    "# The nr of channels used is the question tho ! \n",
    "sinograms, images = square_data_generator(50,64)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1, 64, 180])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sinograms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, side_size = 64, chan1 = 5, chan2 = 10, chan3 = 15) :\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.final_side_size = int(((side_size-4)//3 - 2) //3 - 2)\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, chan1, 5)\n",
    "        self.conv2 = nn.Conv2d(chan1, chan2, 3)\n",
    "        self.conv3 = nn.Conv2d(chan2, chan3, 3)\n",
    "        self.pool = nn.MaxPool2d(3,3) \n",
    "        \n",
    "        self.fc1 = nn.Linear(15 * 16  * self.final_side_size ,500) # what's the first thing coming in ?\n",
    "        self.fc2 = nn.Linear(500,180) # sigmoid act ! \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self,x) :\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # x = self.pool(x)\n",
    "        \n",
    "        \n",
    "        # 16 is what 180 becomes after all the operations, if we apply 1 more maxpool(3,3) at the end we 180 becomes 5 instead\n",
    "        # 15 is the number of channels [ chan3 ! ]\n",
    "        \n",
    "        x = x.view(-1, 15 * 16 * self.final_side_size)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x)) # SIGMOID ! \n",
    "        return x\n",
    "        \n",
    "        \n",
    "#So the counting will go sth like this \n",
    "# Conv2d(input_chan, output chann) -> The next conv2D has got to have input chan equal to prev output channel\n",
    "# Count the ending size like this : \n",
    "# side_size - kernel_size + 1 -> //2 -> -kernel + 1 -> //2 \n",
    "# What chan size should be used !?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4917, 0.5031, 0.4860, 0.4961, 0.5062, 0.4855, 0.4898, 0.5145, 0.4913,\n",
      "         0.4964, 0.5141, 0.4939, 0.4952, 0.5101, 0.4847, 0.5093, 0.4976, 0.4945,\n",
      "         0.4963, 0.5003, 0.5055, 0.5039, 0.5109, 0.5043, 0.5120, 0.5163, 0.5086,\n",
      "         0.4969, 0.4875, 0.4960, 0.4934, 0.4923, 0.5100, 0.4983, 0.4897, 0.4962,\n",
      "         0.5016, 0.5036, 0.5051, 0.5134, 0.5044, 0.5009, 0.4929, 0.4931, 0.5044,\n",
      "         0.4963, 0.4936, 0.4928, 0.5084, 0.4910, 0.4935, 0.4901, 0.5032, 0.4924,\n",
      "         0.5117, 0.4998, 0.4944, 0.5055, 0.5002, 0.5051, 0.5014, 0.5023, 0.4987,\n",
      "         0.5050, 0.5017, 0.4931, 0.4923, 0.5020, 0.5075, 0.5024, 0.4937, 0.5047,\n",
      "         0.4967, 0.4880, 0.4940, 0.4937, 0.4893, 0.5105, 0.5082, 0.5097, 0.5051,\n",
      "         0.5044, 0.5129, 0.5098, 0.4988, 0.5091, 0.5037, 0.4973, 0.5083, 0.4938,\n",
      "         0.5050, 0.4996, 0.5033, 0.5119, 0.4998, 0.5144, 0.5021, 0.4875, 0.4951,\n",
      "         0.4985, 0.4910, 0.5073, 0.4916, 0.4926, 0.4874, 0.4975, 0.5019, 0.4967,\n",
      "         0.4979, 0.4918, 0.5104, 0.5131, 0.4957, 0.5007, 0.4903, 0.4959, 0.5028,\n",
      "         0.5075, 0.5032, 0.4940, 0.4989, 0.5039, 0.5066, 0.5045, 0.4922, 0.5120,\n",
      "         0.4909, 0.4907, 0.4989, 0.5112, 0.4989, 0.4977, 0.4916, 0.4998, 0.4879,\n",
      "         0.4948, 0.5134, 0.4924, 0.4953, 0.5037, 0.4966, 0.4906, 0.5012, 0.4954,\n",
      "         0.5092, 0.5049, 0.4873, 0.4886, 0.5029, 0.4971, 0.4946, 0.5001, 0.5060,\n",
      "         0.5161, 0.5000, 0.4982, 0.4859, 0.4865, 0.5051, 0.4939, 0.5126, 0.5114,\n",
      "         0.5106, 0.5018, 0.4967, 0.4898, 0.5026, 0.5074, 0.4908, 0.5108, 0.4944,\n",
      "         0.5039, 0.5022, 0.5001, 0.4994, 0.5068, 0.4964, 0.5125, 0.5020, 0.5001]],\n",
      "       grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Here, test the forward function - it should output 180 probabilities \n",
    "sinogram, img = square_data_generator(1,64)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "probabilities = Net(sinogram) \n",
    "print(probabilities)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-95de40910560>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mfinal_project_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    992\u001b[0m                                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m                                 \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m                                 accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    995\u001b[0m         \u001b[0;31m# verify that the number of samples given is larger than k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "# Define threshold \n",
    "threshold = 0.51\n",
    "\n",
    "\n",
    "# Choose all projections FROM THAT SINGLE SINOGRAM, that were above given probability\n",
    "projection_list = []\n",
    "for counter, probability in enumerate(probabilities[0]):   # Because probabilities is \n",
    "    if probability >= threshold :\n",
    "        projection = sinogram[0, 0, :, counter]\n",
    "        projection_list.append(projection)\n",
    "        \n",
    "# MAKE THIS LOOP OUTPUT TENSOR OR NUMPY ARRAY, BUT NOT A LIST ??? READ ON KMEANS WITH TENSOR, DOES IT WORKS ?  \n",
    "        \n",
    "        \n",
    "# k-means over all these projections, choose 2 best clusters \n",
    "\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters = 3).fit(projection_list)\n",
    "final_project_list = kmeans.cluster_centers_\n",
    "\n",
    "final_project_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(projection_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define reconstruction function !!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some notes & to-dos \n",
    "\n",
    "->Make sure everyhing is in tensors ! Send numpy arrays to tensors ! [ otherwise the backprob wont work properly ! ] \n",
    "\n",
    "->Is the generator allright? I mean, it's so random? Shouldn't it be more like a square with some white elements within in ? \n",
    "\n",
    "->Why do we use sigmoid ? Instead of Softmax? Softmax would give us probabilities over all of these ! \n",
    "\n",
    "->Do we need to convert y[ img in generator]  to tensor as well? Probs yes so we use GPU to calculate Cross Entropy loss ?\n",
    "\n",
    "->What about normalizing in generator and batch norm layers ? \n",
    "The paper is from 2019, the batch norm has been popular since 2018, so maybe they skipped it on purpose ? \n",
    "\n",
    "->We have to add reconstruction and k-means within the model if we want to feed the batches into it, otherwise we get couple of sinograms but only 1 outputs probabilites, which just doesnt make sense ! \n",
    "\n",
    "->Idea for optimization, as we learn more, we could increase the threshold becaue the model should be more sure about its decisions ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt \n",
    "\n",
    "\n",
    "# !!!! Wrong assumptions !!!!, you know that the 1st dimension is 180, so what's the second one ? \n",
    "def calc_start_img_size(kernel_size) :\n",
    "    img_size = 500\n",
    "    if 500%kernel_size!=0 :\n",
    "        #print(\"Wrong kernel size !\")\n",
    "        a=2\n",
    "    else : \n",
    "        img_size = 500//kernel_size\n",
    "        if not sqrt(img_size).is_integer() :\n",
    "            #print(\"Wrong kernel size !\")\n",
    "            a=2\n",
    "        else :\n",
    "            img_size = sqrt(img_size)\n",
    "            #print(\"img_size : {}, kernel_size : {}\".format(img_size, kernel_size))\n",
    "            #Kernel size is either  5, 20, 125, 500 [ so probs 20 or 5]\n",
    "            \n",
    "            img_size = ((3*img_size+2)*3 + 2)*3 + 4\n",
    "            print(\"img_size : {}, kernel_size : {}\".format(img_size, kernel_size))\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_size : 298.0, kernel_size : 5\n",
      "img_size : 163.0, kernel_size : 20\n",
      "img_size : 82.0, kernel_size : 125\n",
      "img_size : 55.0, kernel_size : 500\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    calc_start_img_size(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((180-4)//3 - 2) //3 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
